{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM8jVnltZ2WdILTfzKXyPoA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QFuC4ZmmN9gJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731645229516,"user_tz":300,"elapsed":169,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"f6ee0983-cd7b-4d3d-af35-47bd795142f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","print(os.getcwd())"]},{"cell_type":"markdown","source":[],"metadata":{"id":"hWkwaFJ0wVBp"}},{"cell_type":"code","source":["!git clone https://github.com/WongKinYiu/yolov7.git\n","!cd yolov7\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6V_GCZWvQy3","executionInfo":{"status":"ok","timestamp":1731645236869,"user_tz":300,"elapsed":4539,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"d66f9d7e-4dfd-4edc-9af2-5362f87f3aea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197 (from 1)\u001b[K\n","Receiving objects: 100% (1197/1197), 74.23 MiB | 25.35 MiB/s, done.\n","Resolving deltas: 100% (519/519), done.\n"]}]},{"cell_type":"code","source":["!pip install -U -r yolov7/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uv-2TGQixECr","executionInfo":{"status":"ok","timestamp":1731623074957,"user_tz":300,"elapsed":191037,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"fd425826-dda0-42d6-f67e-865874e8fffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 4)) (3.8.0)\n","Collecting matplotlib>=3.2.2 (from -r yolov7/requirements.txt (line 4))\n","  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting numpy<1.24.0,>=1.18.5 (from -r yolov7/requirements.txt (line 5))\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 6)) (4.10.0.84)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 7)) (11.0.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 8)) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 9)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 10)) (1.13.1)\n","Collecting scipy>=1.4.1 (from -r yolov7/requirements.txt (line 10))\n","  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 11)) (2.5.0+cu121)\n","Collecting torch!=1.12.0,>=1.7.0 (from -r yolov7/requirements.txt (line 11))\n","  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 12)) (0.20.0+cu121)\n","Collecting torchvision!=0.13.0,>=0.8.1 (from -r yolov7/requirements.txt (line 12))\n","  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 13)) (4.66.6)\n","Collecting tqdm>=4.41.0 (from -r yolov7/requirements.txt (line 13))\n","  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<4.21.3 (from -r yolov7/requirements.txt (line 14))\n","  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 17)) (2.17.0)\n","Collecting tensorboard>=2.4.1 (from -r yolov7/requirements.txt (line 17))\n","  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 21)) (2.2.2)\n","Collecting pandas>=1.1.4 (from -r yolov7/requirements.txt (line 21))\n","  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 22)) (0.13.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 34)) (7.34.0)\n","Collecting ipython (from -r yolov7/requirements.txt (line 34))\n","  Downloading ipython-8.29.0-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov7/requirements.txt (line 35)) (5.9.5)\n","Collecting psutil (from -r yolov7/requirements.txt (line 35))\n","  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n","Collecting thop (from -r yolov7/requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r yolov7/requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov7/requirements.txt (line 9)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov7/requirements.txt (line 9)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov7/requirements.txt (line 9)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov7/requirements.txt (line 9)) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting triton==3.1.0 (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11))\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.12.0,>=1.7.0->-r yolov7/requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (1.67.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (3.7)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (3.1.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov7/requirements.txt (line 21)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov7/requirements.txt (line 21)) (2024.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (4.4.2)\n","Collecting jedi>=0.16 (from ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (0.1.7)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (3.0.48)\n","Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (2.18.0)\n","Collecting stack-data (from ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n","Collecting traitlets>=5.13.0 (from ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (1.2.2)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r yolov7/requirements.txt (line 34)) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r yolov7/requirements.txt (line 34)) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r yolov7/requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r yolov7/requirements.txt (line 34)) (0.2.13)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r yolov7/requirements.txt (line 17)) (3.0.2)\n","Collecting executing>=1.2.0 (from stack-data->ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n","Collecting asttokens>=2.1.0 (from stack-data->ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n","Collecting pure-eval (from stack-data->ipython->-r yolov7/requirements.txt (line 34))\n","  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ipython-8.29.0-py3-none-any.whl (819 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.9/819.9 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n","Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n","Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n","Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n","Installing collected packages: pure-eval, triton, traitlets, tqdm, psutil, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, jedi, executing, asttokens, tensorboard, stack-data, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, matplotlib, ipython, torch, torchvision, thop\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.7.1\n","    Uninstalling traitlets-5.7.1:\n","      Successfully uninstalled traitlets-5.7.1\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.66.6\n","    Uninstalling tqdm-4.66.6:\n","      Successfully uninstalled tqdm-4.66.6\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.9.5\n","    Uninstalling psutil-5.9.5:\n","      Successfully uninstalled psutil-5.9.5\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n","    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n","    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.0\n","    Uninstalling tensorboard-2.17.0:\n","      Successfully uninstalled tensorboard-2.17.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n","    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.8.0\n","    Uninstalling matplotlib-3.8.0:\n","      Successfully uninstalled matplotlib-3.8.0\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 7.34.0\n","    Uninstalling ipython-7.34.0:\n","      Successfully uninstalled ipython-7.34.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.0+cu121\n","    Uninstalling torch-2.5.0+cu121:\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["os.chdir('/content/yolov7')\n","print(\"Current Directory:\", os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pX33ndocoLbr","executionInfo":{"status":"ok","timestamp":1731645253287,"user_tz":300,"elapsed":248,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"7a7714cf-1220-4c8c-bf86-4b55e5a9264c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Directory: /content/yolov7\n"]}]},{"cell_type":"code","source":["!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTPmPrATrUne","executionInfo":{"status":"ok","timestamp":1731645260768,"user_tz":300,"elapsed":1284,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"d709dc17-4bfd-4ea6-8b8e-49ae255d8ea6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-15 04:34:19--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241115T043419Z&X-Amz-Expires=300&X-Amz-Signature=6615afcf5133aa8c7905505d2769f5bb5eaa2ed111cebe78aa686a01f27710a6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n","--2024-11-15 04:34:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241115T043419Z&X-Amz-Expires=300&X-Amz-Signature=6615afcf5133aa8c7905505d2769f5bb5eaa2ed111cebe78aa686a01f27710a6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75587165 (72M) [application/octet-stream]\n","Saving to: ‘yolov7.pt’\n","\n","yolov7.pt           100%[===================>]  72.08M   152MB/s    in 0.5s    \n","\n","2024-11-15 04:34:20 (152 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n","\n"]}]},{"cell_type":"code","source":["import albumentations as A\n","import cv2\n","import os\n","import glob\n","import random\n","\n","# Define augmentation pipeline\n","transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomRotate90(p=0.5),\n","    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),\n","    A.RandomBrightnessContrast(p=0.5),\n","    A.GaussNoise(p=0.2),\n","    A.Blur(blur_limit=3, p=0.3),\n","], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n","\n","# Paths to input and output directories\n","input_image_dir = \"/content/yolov7/dataset/images/\"          # directory with your original images\n","input_label_dir = \"/content/yolov7/dataset/labels/\"           # directory with YOLO-format .txt files\n","output_image_dir = \"/content/yolov7/dataset/augmented_images/\"\n","output_label_dir = \"/content/yolov7/dataset/augmented_labels/\"\n","\n","# Make directories if they don't exist\n","os.makedirs(output_image_dir, exist_ok=True)\n","os.makedirs(output_label_dir, exist_ok=True)\n","\n","# Function to apply augmentation\n","def augment_image(image_path, label_path, save_prefix=\"aug\"):\n","    # Load image\n","    image = cv2.imread(image_path)\n","    height, width = image.shape[:2]\n","\n","    # Load bounding boxes from YOLO-format .txt file\n","    bboxes = []\n","    class_labels = []\n","    with open(label_path, 'r') as f:\n","        for line in f:\n","            class_id, x_center, y_center, bbox_width, bbox_height = map(float, line.strip().split())\n","            bboxes.append([x_center, y_center, bbox_width, bbox_height])\n","            class_labels.append(int(class_id))\n","\n","    # Apply augmentation\n","    augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n","    aug_image = augmented['image']\n","    aug_bboxes = augmented['bboxes']\n","    aug_labels = augmented['class_labels']\n","\n","    # Save augmented image\n","    aug_image_name = os.path.join(output_image_dir, f\"{save_prefix}_{os.path.basename(image_path)}\")\n","    cv2.imwrite(aug_image_name, aug_image)\n","\n","    # Save augmented bounding boxes in YOLO format\n","    aug_label_name = os.path.join(output_label_dir, f\"{save_prefix}_{os.path.basename(label_path)}\")\n","    with open(aug_label_name, 'w') as f:\n","        for class_id, (x_center, y_center, bbox_width, bbox_height) in zip(aug_labels, aug_bboxes):\n","            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n","\n","# Augment each image in the directory multiple times\n","num_augmentations = 15  # Number of augmented copies per image\n","for image_path in glob.glob(os.path.join(input_image_dir, \"*.jpg\")):\n","    base_name = os.path.basename(image_path)\n","    label_path = os.path.join(input_label_dir, base_name.replace(\".jpg\", \".txt\"))\n","\n","    for i in range(num_augmentations):\n","        augment_image(image_path, label_path, save_prefix=f\"aug_{i}\")\n"],"metadata":{"id":"hvUTyMnrImTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_path in glob.glob(os.path.join(input_image_dir, \"*.png\")):\n","    base_name = os.path.basename(image_path)\n","    label_path = os.path.join(input_label_dir, base_name.replace(\".png\", \".txt\"))\n","\n","    for i in range(num_augmentations):\n","        augment_image(image_path, label_path, save_prefix=f\"aug_{i}\")"],"metadata":{"id":"IW02tC6rL6la"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","\n","# Paths to the main image and label directories\n","input_image_dir = \"/content/yolov7/dataset/augmented_images/\"\n","input_label_dir = \"/content/yolov7/dataset/augmented_labels/\"\n","\n","# Define paths for train and validation directories\n","train_image_dir = \"/content/yolov7/dataset/images/train/\"\n","train_label_dir = \"/content/yolov7/dataset/labels/train/\"\n","val_image_dir = \"/content/yolov7/dataset/images/val/\"\n","val_label_dir = \"/content/yolov7/dataset/labels/val/\"\n","\n","# Create directories if they don't exist\n","os.makedirs(train_image_dir, exist_ok=True)\n","os.makedirs(train_label_dir, exist_ok=True)\n","os.makedirs(val_image_dir, exist_ok=True)\n","os.makedirs(val_label_dir, exist_ok=True)\n","\n","# Set the split ratio\n","train_ratio = 0.8  # 80% for training, 20% for validation\n","\n","# Get list of all image files (both .jpg and .png)\n","image_files = glob.glob(os.path.join(input_image_dir, \"*.jpg\")) + glob.glob(os.path.join(input_image_dir, \"*.png\"))\n","# Shuffle the list for random splitting\n","random.shuffle(image_files)\n","\n","# Calculate split index\n","split_index = int(len(image_files) * train_ratio)\n","\n","# Split into train and validation\n","train_files = image_files[:split_index]\n","val_files = image_files[split_index:]\n","\n","# Function to copy files to their respective directories\n","def copy_files(file_list, image_dir, label_dir):\n","    for image_path in file_list:\n","        # Copy image file\n","        base_name = os.path.basename(image_path)\n","        # Change the file extension to .txt for label file matching\n","        label_path = os.path.join(input_label_dir, os.path.splitext(base_name)[0] + \".txt\")\n","\n","        if os.path.exists(label_path):  # Ensure corresponding label exists\n","            # Copy image to destination folder\n","            shutil.copy(image_path, image_dir)\n","            # Copy label to destination folder\n","            shutil.copy(label_path, label_dir)\n","\n","# Copy train and validation files\n","copy_files(train_files, train_image_dir, train_label_dir)\n","copy_files(val_files, val_image_dir, val_label_dir)\n","\n","print(f\"Training set: {len(train_files)} images\")\n","print(f\"Validation set: {len(val_files)} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fb5HpjpiNGCm","executionInfo":{"status":"ok","timestamp":1731647292961,"user_tz":300,"elapsed":10145,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"c693acfd-06a8-405a-9577-092a28804df2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: 336 images\n","Validation set: 84 images\n"]}]},{"cell_type":"code","source":["!python train.py --img 640 --batch 16 --epochs 20 --data damage_colab.yaml --weights yolov7.pt --name yolov7-damage-detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-n3rkB3sOtV","executionInfo":{"status":"ok","timestamp":1731649453746,"user_tz":300,"elapsed":2048412,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"0242a1df-4e17-411c-ce2e-39239de7d74e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-15 05:10:07.319772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-15 05:10:07.339493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-15 05:10:07.345313: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-15 05:10:07.360427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-15 05:10:08.356437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='', data='damage_colab.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=20, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7-damage-detection', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-damage-detection', total_batch_size=16)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","/content/yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20241115_051110-bblkvrr0\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov7-damage-detection\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ts22u-florida-state-university/YOLOR\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ts22u-florida-state-university/YOLOR/runs/bblkvrr0\u001b[0m\n","/content/yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n","Overriding model.yaml nc=80 with nc=6\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     59235  models.yolo.Detect                      [6, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","Model Summary: 407 layers, 37221635 parameters, 37221635 gradients\n","\n","Transferred 554/560 items from yolov7.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov7/dataset/labels/train' images and labels... 336 found, 0 missing, 0 empty, 0 corrupted: 100% 336/336 [00:01<00:00, 177.02it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov7/dataset/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov7/dataset/labels/val' images and labels... 84 found, 0 missing, 0 empty, 0 corrupted: 100% 84/84 [00:01<00:00, 83.35it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov7/dataset/labels/val.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.50, Best Possible Recall (BPR) = 0.9635. Attempting to improve anchors, please wait...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 237 of 8593 labels are < 3 pixels in size.\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 8565 points...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9796 best possible recall, 4.90 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.327/0.761-mean/best, past_thr=0.525-mean: 9,8,  12,16,  19,11,  24,20,  42,14,  17,42,  168,28,  49,251,  248,303\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7801: 100% 1000/1000 [00:13<00:00, 76.83it/s]\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9796 best possible recall, 5.61 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.374/0.780-mean/best, past_thr=0.553-mean: 8,8,  10,11,  18,9,  15,14,  14,27,  24,18,  115,38,  69,282,  201,321\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n","\n","/content/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = amp.GradScaler(enabled=cuda)\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov7-damage-detection\n","Starting training for 20 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","  0% 0/21 [00:00<?, ?it/s]/content/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(enabled=cuda):\n","      0/19     13.3G    0.1058   0.02723   0.02952    0.1625       773       640: 100% 21/21 [01:33<00:00,  4.45s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:19<00:00,  6.65s/it]\n","                 all          84        2469    0.000334      0.0512    2.79e-05    3.28e-06\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      1/19     13.1G    0.1013   0.02833   0.02627    0.1559       792       640: 100% 21/21 [01:12<00:00,  3.46s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:06<00:00,  2.24s/it]\n","                 all          84        2469     0.00197      0.0268    0.000101     1.6e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      2/19     12.3G   0.09472   0.03043   0.02143    0.1466       936       640: 100% 21/21 [01:17<00:00,  3.68s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.06it/s]\n","                 all          84        2469       0.261      0.0215     0.00214    0.000339\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      3/19     12.3G   0.09257   0.02935   0.01862    0.1405       932       640: 100% 21/21 [01:24<00:00,  4.02s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:08<00:00,  2.90s/it]\n","                 all          84        2469       0.779      0.0582      0.0129     0.00229\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      4/19     14.6G   0.08651   0.02968    0.0178     0.134      1031       640: 100% 21/21 [01:17<00:00,  3.71s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:04<00:00,  1.40s/it]\n","                 all          84        2469       0.796      0.0748      0.0293     0.00546\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      5/19     14.6G   0.08443   0.02991   0.01661     0.131       925       640: 100% 21/21 [01:23<00:00,  3.98s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:06<00:00,  2.32s/it]\n","                 all          84        2469       0.813      0.0858      0.0423     0.00909\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      6/19     14.6G   0.08448   0.03143   0.01468    0.1306       811       640: 100% 21/21 [01:22<00:00,  3.91s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.01s/it]\n","                 all          84        2469       0.822      0.0924       0.049      0.0113\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      7/19     14.6G   0.08045   0.03504    0.0146    0.1301       752       640: 100% 21/21 [01:18<00:00,  3.73s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:07<00:00,  2.39s/it]\n","                 all          84        2469       0.562       0.103      0.0498      0.0124\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      8/19     14.7G   0.08235   0.03396    0.0146    0.1309       873       640: 100% 21/21 [01:22<00:00,  3.91s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:05<00:00,  1.91s/it]\n","                 all          84        2469       0.792      0.0973      0.0346     0.00733\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","      9/19     14.7G   0.07966   0.03471   0.01414    0.1285       793       640: 100% 21/21 [01:22<00:00,  3.91s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:09<00:00,  3.31s/it]\n","                 all          84        2469       0.559       0.102      0.0466      0.0095\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     10/19     14.7G   0.07704   0.03605   0.01329    0.1264       612       640: 100% 21/21 [01:26<00:00,  4.13s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.06it/s]\n","                 all          84        2469        0.83       0.103      0.0672      0.0164\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     11/19     14.7G   0.07684   0.03867   0.01356    0.1291       877       640: 100% 21/21 [01:14<00:00,  3.54s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:09<00:00,  3.22s/it]\n","                 all          84        2469       0.806      0.0967      0.0429     0.00928\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     12/19     14.7G   0.07214    0.0394   0.01151     0.123       883       640: 100% 21/21 [01:26<00:00,  4.14s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.06s/it]\n","                 all          84        2469       0.838       0.122      0.0786      0.0217\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     13/19     14.7G   0.07181   0.03841   0.01223    0.1224       922       640: 100% 21/21 [01:18<00:00,  3.72s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:07<00:00,  2.39s/it]\n","                 all          84        2469        0.85       0.132      0.0953      0.0283\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     14/19     14.7G   0.07293   0.04053   0.01228    0.1257      1060       640: 100% 21/21 [01:22<00:00,  3.92s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.03s/it]\n","                 all          84        2469       0.841       0.116      0.0871      0.0231\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     15/19     14.7G   0.07028   0.04129   0.01195    0.1235       719       640: 100% 21/21 [01:24<00:00,  4.05s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:09<00:00,  3.20s/it]\n","                 all          84        2469       0.854       0.112      0.0933      0.0261\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     16/19     14.7G   0.06951   0.04298   0.01148     0.124       536       640: 100% 21/21 [01:25<00:00,  4.06s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.19s/it]\n","                 all          84        2469       0.867       0.151       0.132      0.0462\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     17/19     14.7G   0.06629   0.03982  0.009911     0.116       782       640: 100% 21/21 [01:13<00:00,  3.50s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:10<00:00,  3.34s/it]\n","                 all          84        2469       0.871       0.152       0.135      0.0479\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     18/19     14.7G   0.06731   0.04031   0.01085    0.1185       778       640: 100% 21/21 [01:16<00:00,  3.66s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.05s/it]\n","                 all          84        2469       0.874       0.154       0.137      0.0486\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     19/19     14.7G   0.06575   0.04242   0.01014    0.1183       871       640: 100% 21/21 [01:15<00:00,  3.60s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 3/3 [00:13<00:00,  4.55s/it]\n","                 all          84        2469       0.884       0.148       0.146      0.0547\n","               Other          84          15           1           0    0.000462    0.000231\n","              Damage          84         374           1           0      0.0572      0.0207\n","       Broken Window          84        2069       0.535       0.593       0.526       0.198\n","                Roof          84          11           1           0           0           0\n","Images sizes do not match. This will causes images to be display incorrectly in the UI.\n","20 epochs completed in 0.541 hours.\n","\n","/content/yolov7/utils/general.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  x = torch.load(f, map_location=torch.device('cpu'))\n","Optimizer stripped from runs/train/yolov7-damage-detection/weights/last.pt, 74.8MB\n","Optimizer stripped from runs/train/yolov7-damage-detection/weights/best.pt, 74.8MB\n","Images sizes do not match. This will causes images to be display incorrectly in the UI.\n","\u001b[34m\u001b[1mwandb\u001b[0m: 110.403 MB of 149.472 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: 149.472 MB of 149.472 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: 149.479 MB of 149.479 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: 149.479 MB of 149.479 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: 149.479 MB of 149.479 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▂▂▃▃▃▃▃▄▃▅▆▅▅▇▇██\n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▂▂▂▃▂▂▃▂▄▅▄▄▇▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▃▇▇▇█▅▇▅█▇████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▃▁▁▃▄▄▅▅▅▅▅▅▆▇▆▆████\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▆▆▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▁▂▂▂▂▃▄▄▄▅▆▆▆▇▇█▇▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▆▅▅▄▄▄▄▄▃▃▂▂▂▂▁▁▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▆▅▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▃▄▄▅▆▆▇▆▇█▇▇██▇█▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▂▄▅▆▇▇████▇▇▆▅▅▄▃▃▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▂▄▅▆▇▇████▇▇▆▅▅▄▃▃▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14597\n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05469\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.88384\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.14826\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.06575\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01014\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.04242\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.12176\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01525\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.09661\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00044\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00044\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.05854\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov7-damage-detection\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ts22u-florida-state-university/YOLOR/runs/bblkvrr0\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/ts22u-florida-state-university/YOLOR\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 342 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241115_051110-bblkvrr0/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/196937.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83LkW-VmymhP","executionInfo":{"status":"ok","timestamp":1731649521436,"user_tz":300,"elapsed":17389,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"7c4feff4-e497-4f19-c842-ba9fe28e6d6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/196937.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","8 Broken Windows, Done. (16.5ms) Inference, (693.1ms) NMS\n"," The image with the result is saved in: runs/detect/exp2/196937.jpg\n","Done. (1.039s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/Taj.jpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thczXALr6ZAh","executionInfo":{"status":"ok","timestamp":1731649586687,"user_tz":300,"elapsed":17308,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"3c9c52a4-e206-4e40-9e1a-a7e1742e6c82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/Taj.jpeg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","1 Broken Window, Done. (16.5ms) Inference, (429.0ms) NMS\n"," The image with the result is saved in: runs/detect/exp3/Taj.jpeg\n","Done. (0.995s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/Cathedral.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLTwat2tWv3x","executionInfo":{"status":"ok","timestamp":1731649612773,"user_tz":300,"elapsed":17025,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"3b28f450-b150-49d1-a203-532edf2ef066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/Cathedral.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","8 Broken Windows, Done. (17.4ms) Inference, (457.8ms) NMS\n"," The image with the result is saved in: runs/detect/exp4/Cathedral.jpg\n","Done. (0.682s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmbnhEszUqzs","executionInfo":{"status":"ok","timestamp":1731649635705,"user_tz":300,"elapsed":18029,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"05974775-05c4-4575-eecb-2a6875a4ecad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","9 Broken Windows, Done. (14.9ms) Inference, (724.0ms) NMS\n"," The image with the result is saved in: runs/detect/exp5/download1.png\n","Done. (1.136s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1_1.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrEv6kkE6uJn","executionInfo":{"status":"ok","timestamp":1731649656928,"user_tz":300,"elapsed":17181,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"1bb89130-e5b5-4f8a-c855-c7a425b4ad09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1_1.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","13 Broken Windows, Done. (14.8ms) Inference, (532.1ms) NMS\n"," The image with the result is saved in: runs/detect/exp6/download1_1.png\n","Done. (0.860s)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"742VUPQJUGhE"}},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1_3.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfivGYdt6yX-","executionInfo":{"status":"ok","timestamp":1731649686677,"user_tz":300,"elapsed":16732,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"c96690a3-6b8b-4ec2-8376-4abf8a4e5c07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1_3.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Done. (15.1ms) Inference, (9.0ms) NMS\n"," The image with the result is saved in: runs/detect/exp7/download1_3.png\n","Done. (0.300s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1_4.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDT6NsT-6zjT","executionInfo":{"status":"ok","timestamp":1731649715636,"user_tz":300,"elapsed":17490,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"ab7de7de-af61-40ba-fc1c-332397568bef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1_4.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","12 Broken Windows, Done. (14.9ms) Inference, (684.8ms) NMS\n"," The image with the result is saved in: runs/detect/exp8/download1_4.png\n","Done. (1.016s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1_5.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADyGfyCEUvWo","executionInfo":{"status":"ok","timestamp":1731649742752,"user_tz":300,"elapsed":17386,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"7a76acf8-fdcd-4566-a367-4118c44d3d07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1_5.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","5 Broken Windows, Done. (14.8ms) Inference, (615.2ms) NMS\n"," The image with the result is saved in: runs/detect/exp9/download1_5.png\n","Done. (0.943s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download1_6.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZaekdI2UyBC","executionInfo":{"status":"ok","timestamp":1731649770484,"user_tz":300,"elapsed":17444,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"8749651c-d9c0-479d-e0f6-a2d4760973fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download1_6.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Done. (14.8ms) Inference, (13.6ms) NMS\n"," The image with the result is saved in: runs/detect/exp10/download1_6.png\n","Done. (0.470s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download2_1.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81awgWsKU0SK","executionInfo":{"status":"ok","timestamp":1731649789921,"user_tz":300,"elapsed":16719,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"ae3adede-3ae3-4fb8-bf21-af1eab6b680f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download2_1.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Done. (14.9ms) Inference, (8.5ms) NMS\n"," The image with the result is saved in: runs/detect/exp11/download2_1.png\n","Done. (0.266s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/palace.jpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orAZq50dXvVI","executionInfo":{"status":"ok","timestamp":1731649828791,"user_tz":300,"elapsed":16827,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"a60aa71b-934f-402c-b5d7-5c582e81e026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/palace.jpeg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","8 Broken Windows, Done. (14.9ms) Inference, (508.4ms) NMS\n"," The image with the result is saved in: runs/detect/exp12/palace.jpeg\n","Done. (0.722s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/palace2.jpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mysfhb-7Xzw5","executionInfo":{"status":"ok","timestamp":1731649856831,"user_tz":300,"elapsed":18015,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"7b86ce65-0e37-4599-bb17-bb0e38d65b68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/palace2.jpeg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","17 Broken Windows, Done. (16.6ms) Inference, (944.9ms) NMS\n"," The image with the result is saved in: runs/detect/exp13/palace2.jpeg\n","Done. (1.207s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download4_2.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOJoZppFbB3n","executionInfo":{"status":"ok","timestamp":1731650697044,"user_tz":300,"elapsed":17156,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"ec216f1e-fdd8-44bf-bb19-ac88b5a1d6e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download4_2.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","33 Broken Windows, Done. (14.8ms) Inference, (530.0ms) NMS\n"," The image with the result is saved in: runs/detect/exp14/download4_2.png\n","Done. (0.869s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/download5.png"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igkszh5ibIRC","executionInfo":{"status":"ok","timestamp":1731650720495,"user_tz":300,"elapsed":17640,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"fe22fdef-ec8c-452a-92b2-ffa535170f4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/download5.png', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","103 Broken Windows, Done. (14.8ms) Inference, (683.0ms) NMS\n"," The image with the result is saved in: runs/detect/exp15/download5.png\n","Done. (1.074s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/building.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmKyccGjcIFX","executionInfo":{"status":"ok","timestamp":1731650992877,"user_tz":300,"elapsed":18319,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"38f455ea-dde0-4f86-e452-1cf449c9e559"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/building.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","29 Broken Windows, Done. (17.1ms) Inference, (498.3ms) NMS\n"," The image with the result is saved in: runs/detect/exp16/building.jpg\n","Done. (0.750s)\n"]}]},{"cell_type":"code","source":["!python detect.py --weights /content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt --img 640 --conf 0.25 --source /content/yolov7/dataset/check/office.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbRl0QzicI8_","executionInfo":{"status":"ok","timestamp":1731651012736,"user_tz":300,"elapsed":16670,"user":{"displayName":"Taniya Sarkar","userId":"13079124673143382932"}},"outputId":"416c241e-fe79-4d51-d441-a0bd3572dd63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights=['/content/yolov7/runs/train/yolov7-damage-detection/weights/best.pt'], source='/content/yolov7/dataset/check/office.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n","\n","/content/yolov7/models/experimental.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(w, map_location=map_location)  # load\n","Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","Model Summary: 306 layers, 36506851 parameters, 6194944 gradients\n"," Convert model to Traced-model... \n"," traced_script_module saved! \n"," model is traced! \n","\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Done. (16.2ms) Inference, (5.8ms) NMS\n"," The image with the result is saved in: runs/detect/exp17/office.jpg\n","Done. (0.138s)\n"]}]}]}